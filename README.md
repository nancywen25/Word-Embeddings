# Word-Embeddings
Explore the benefits of word embeddings for NLP tasks

### Task 1: Word Similarity
This task measures how well word embeddings can reproduce human judgements regarding the similarity of words. Using 500 dimension GloVe vectors, we calculated cosine similarity between word embeddings. The embeddings similarity score and the human similarity score had a Pearson correlation of 0.71. See output [here](https://github.com/nancywen25/Word-Embeddings/blob/master/output/word_similarity.txt).
